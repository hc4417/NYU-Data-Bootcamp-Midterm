# -*- coding: utf-8 -*-
"""api_midterm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SCRo4VyssS0pHJ15O9myKc081GvJ4Vca

## Midterm Project

**Scraping websites + cleaning**
"""

import requests
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from bs4 import BeautifulSoup
import re

"""Nili Lotan Data (small/medium sized luxury boutique)"""

# Nili Lotan Product Scraper
def nili_product_webscraper(url):
  # Request and turn catalog to soup
  r = requests.get(url)
  retailer_soup = BeautifulSoup(r.text, 'html.parser')

  # Find product listings
  product = retailer_soup.find_all('div', {'class': 'product-item'})
  product_data = []

  # Loop through listings and add needed product details to list
  for listing in product:
    vendor = 'Nili Lotan'
    name = listing.find('p', {'class': 'product-item__title'})
    category  = name.text.split()[-1]
    price = listing.find('span', {'class': 'new-price'})
    product_link = listing.find('a', {'class': 'product-link product-item__info'}).get('href')

    # Request and turn product page to soup
    product_link = 'https://nililotan.com'+ product_link
    p = requests.get(product_link)
    product_page_soup = BeautifulSoup(p.text, 'html.parser')

    # Extract necessary product details
    product_desc = product_page_soup.find('div', {'class': 'product__description-text'})
    if product_desc:
      product_desc = product_desc.text.split()

    size_guide = bool(product_page_soup.find('a', {'class': 'nili-openButton size-guide-btn'}))

    # create a set of product vocabulary
    set_desc = set(product_desc)

    # return the quotient of appropriate lengths
    len_desc = len(product_desc)
    lex_diversity = (len(set_desc)/len_desc)*100

    product_desc = ' '.join(product_desc)
    product_details  = product_page_soup.find('ul', {'class': 'product__description-below'}).text

    # number of product pictures
    #pictures = product_page_soup.find_all('div', class_ = 'product__thumbnail-image')
    pictures = product_page_soup.select('div.product__thumbnail-image img')
    pic_count = len(pictures)

    # Check for null prices before turning to float
    if price:
      price = price.text.split()
      price = ''.join(price)
      price = price.replace("$", "").replace(",", "")
      price = float(price)

      if price < 500:
        price_tag = 'Affordable fashion'

      elif price < 2000:
        price_tag = 'Accessible Luxury'

      elif price < 10000:
        price_tag = 'High Luxury'

      else:
        price_tag = 'Ultra Luxury'

    product_data.append({
        'Retailer': 'Nili Lotan',
        'Vendor': vendor,
        'Category': category,
        'Name': name,
        'Price': price,
        'Product Link': product_link,
        'Description': product_desc,
        'Product Details': product_details,
        'Description Lexical Diversity':lex_diversity,
        'Description Length': len_desc,
        'Size Guide': size_guide,
        'Luxury Tier': price_tag,
        'Number of pictures' : pic_count
    })

  # Create DataFrame
  product_df = pd.DataFrame(product_data)
  return product_df

nili_df = nili_product_webscraper('https://www.nililotan.com/collections/all-womens')
nili_df

"""IFSOHO DATA
(some products are sold out, and without price, can discuss later if we need to remove them)
"""

# Request and turn catalog to soup
url = 'https://ifsohonewyork.com/collections/all'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

products_list = []

# Find all product listings
products = soup.find_all('div', class_='product-index')
categories = ['Boots', 'Jacket', 'Robe', 'Shirt', 'Dress', 'Pant', 'Hood', 'Bomber',
              'Coat', 'Blazer', 'Waistcoat', 'Trousers', 'Trouser', 'Blouse', 'Jumper',
              'Derby', 'Jupe', 'Veste', 'Pull', 'Sweater','Cape', 'Cardigan', 'Top', 'Vest']

for product in products:
    name = product.find('h3')
    price = product.find('div', class_='prod-price')
    vendor = product.find('p', class_='vendor-name')

    # Retrieve category
    for word in name.text.split():
      if word in categories:
        category = word.upper()

    a_tag = product.find("a", href=True)
    base_url = 'https://ifsohonewyork.com'

    # Request and turn product page to soup
    product_url = base_url + a_tag['href']
    a_response = requests.get(product_url)
    a_soup = BeautifulSoup(a_response.text, 'html.parser')
    description = a_soup.find('div', class_='description').text.split()
    size_guide = bool(a_soup.find('span', {'class': 'view-size'}))

    # create a set of product vocabulary
    set_desc = set(description)

    # return the quotient of appropriate lengths
    len_desc = len(description)
    lex_diversity = (len(set_desc)/len_desc)*100

    # number of product pictures
    pictures = a_soup.find_all('div', class_ = 'mthumb')
    pic_count = len(pictures)

    # categorize price
    '''
    ultra-luxury -> $10000+
    high luxury -> $2000 - $10000
    accessible luxury -> $500 - $2000
    affordable fashion -> below $500
    '''
    if price:
      price = price.text.split()
      price = ''.join(price)
      price = price.replace("$", "").replace(",", "")
      price = float(price)

    if not price:
        continue

    if price < 500:
      price_tag = 'Affordable fashion'

    elif price < 2000:
      price_tag = 'Accessible Luxury'

    elif price < 10000:
      price_tag = 'High Luxury'

    else:
      price_tag = 'Ultra Luxury'

    description = ' '.join(description)
    products_list.append({
        'Retailer': 'IF SOHO',
        'Vendor' : vendor,
        'Category': category,
        'Name' : name,
        'Price' : price,
        'Product Link': product_url,
        'Description' : description,
        'Product Details' : description,
        'Description Lexical Diversity': lex_diversity,
        'Description Length': len_desc,
        'Size Guide': size_guide,
        'Luxury Tier': price_tag,
        'Number of pictures':pic_count})

ifsoho_df = pd.DataFrame(products_list)
ifsoho_df

"""La Garconne"""

lagarconne_product_list = []

# run through the first 2 pages of the website
for lagarconne_page in range(1, 2):
    lagarconne_url = f'https://lagarconne.com/collections/all?page={lagarconne_page}'
    lagarconne_response = requests.get(lagarconne_url)
    lagarconne_soup = BeautifulSoup(lagarconne_response.text, 'html.parser')

    lagarconne_products = lagarconne_soup.find_all('div', class_="lg-col-6 lg-col-md-3 lg-product-list-item")

    for product in lagarconne_products:
        name = product.find('h3', class_="lg-product-list-item-title")
        price = product.find('span', class_="money")
        vendor = product.find('p', class_="lg-product-list-item-vendor")

        name_text = name.get_text(strip=True) if name else None
        price_text = price.get_text(strip=True) if price else None
        price_value = float(price_text.replace('$', '').replace(',', '')) if price_text else None

        if price_value:
          if price_value < 500:
            price_tag = 'Affordable fashion'

          elif price_value < 2000:
            price_tag = 'Accessible Luxury'

          elif price_value < 10000:
            price_tag = 'High Luxury'

          else:
            price_tag = 'Ultra Luxury'

        vendor_text = vendor.get_text(strip=True) if vendor else None

        # Extract product link
        link_tag = product.find('a', href=True)
        if not link_tag:
            continue
        product_link = 'https://lagarconne.com' + link_tag['href']
        p = requests.get(product_link)
        product_page_soup = BeautifulSoup(p.text, 'html.parser')

        # description
        desc_div = product_page_soup.find('div', class_="lg-desc-product lg-col-md-8 lg-no-gutters")
        descrip = desc_div.find('p')
        product_desc = descrip.get_text(" ", strip=True).split()

        # Lexical diversity
        set_desc = set(product_desc)
        len_desc = len(product_desc)
        lex_diversity = round(len(set_desc)/len_desc*100, 2)
        product_desc_str = ' '.join(product_desc)

        # Product details (paragraph with non-breaking space)
        details = desc_div.find('p', string=lambda t: t and "Color:" in t)
        product_details = details.get_text(" ", strip=True) if details else None

        # Size guide presence
        size_guide = bool(product_page_soup.find('a', {'class': 'lg-link product-sizechart'}))

        if not price_text:
            continue
        # number of product pictures
        pictures = product_page_soup.find_all('div', class_='lg-product-item')
        pic_count = len(pictures)
        #print(pic_count)

        # category extraction
        category = (name_text.split('—')[0].split()[-1].upper()
                    if name_text and '—' in name_text
                    else (name_text.split()[-1] if name_text else None))

        if category in ['Perfume', 'Bar', 'Gel', 'Lotion', 'Wash']:
          category = 'Home supplies'
        elif category == 'Rejuven8':
          category = 'Sneaker'

        # append list
        lagarconne_product_list.append({
            'Retailer': 'La Garconne',
            'Vendor': vendor_text,
            'Name': name_text,
            'Price': price_value,
            'Category': category,
            'Product Link': product_link,
            'Description': product_desc_str,
            'Product Details': product_details,
            'Description Lexical Diversity': lex_diversity,
            'Description Length': len_desc,
            'Size Guide': size_guide,
            'Luxury Tier': price_tag,
            'Number of pictures' : pic_count
        })

# DataFrame
lagar_df = pd.DataFrame(lagarconne_product_list)
lagar_df

"""**Data Visualizations**

Combining DataFrames
"""

# Combine dataframes
combined_df = pd.concat([lagar_df, ifsoho_df, nili_df], ignore_index=True)

# check all products carried through
print(len(lagar_df) + len(ifsoho_df) + len(nili_df))
print(len(combined_df))

"""**Big Question 1**: What types of products do competitors offer?

What is the distribution of product types across local competitors?
"""

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

# La Garconne
lagar_df['Category'].value_counts().plot(
    kind='barh',
    ax=axes[0]
)
axes[0].set_title('La Garçonne', fontsize=13)
axes[0].set_xlabel('Count')
axes[0].set_ylabel('Category')

# Nili Lotan
nili_df['Category'].value_counts().plot(
    kind='barh',
    ax=axes[1]
)
axes[1].set_title('Nili Lotan', fontsize=13)
axes[1].set_xlabel('Count')
axes[1].set_ylabel('')

#IF SOHO
ifsoho_df['Category'].value_counts().plot(
    kind='barh',
    ax=axes[2]
)
axes[2].set_title('If SOHO NEW YORK', fontsize=13)
axes[2].set_xlabel('Count')
axes[2].set_ylabel('')

plt.suptitle('Category Distribution by Retailer', fontsize=16)
plt.show()

""" What tier of luxury do they fall into?"""

retailers = combined_df['Retailer'].unique()

# Create a grid of subplots
fig, axes = plt.subplots(1, len(retailers), figsize=(14, 5))

for i, retailer in enumerate(retailers):
    # Subset data for this retailer
    subset = combined_df[combined_df['Retailer'] == retailer]
    tier_counts = subset['Luxury Tier'].value_counts()

    # Plot pie chart
    axes[i].pie(
        tier_counts,
        labels=tier_counts.index,
        autopct='%1.1f%%',
        startangle=90,
        colors=['#c1d3fe', '#a7c7e7', '#779ecb']
    )
    axes[i].set_title(f'{retailer}\nLuxury Tier Distribution')

# Labels and Formatting
plt.suptitle('Distribution of Products Across Luxury Tiers', fontsize=14, fontweight='bold')
plt.tight_layout()

"""**Big Question 2**: How are competitors pricing their products?"""

# Creating df that takes into account combined retailer products
plot_df = combined_df.copy()
total_df = plot_df.copy()
total_df['Retailer'] = 'Total'

combined_plot_df = pd.concat([plot_df, total_df])

# Creating boxplot
combined_plot_df.boxplot(column='Price', by='Retailer', grid=False)
plt.title('Price Comparison Across Retailers')
plt.suptitle('')  # removes default pandas title
plt.ylabel('Price ($)')

"""**Big Question 3:** What product information do our competitors give customers?

Is there a relationship between product price and description length?
"""

sns.lmplot(
    data=combined_df,
    x='Description Length',
    y='Price',
    height=6,
    aspect=1.4,
    scatter_kws={'alpha':0.4}
)

# Labels
plt.title('Price vs Description Length by Retailer')
plt.xlabel('Description Length (words)')
plt.ylabel('Price ($)')

# Finding correlation
correlation = combined_df['Price'].corr(combined_df['Description Length'])
print(f"The correlation between Price and Description Length is: {correlation:.2f}")

"""How often do retailers provide size guides?"""

size_guide_counts = combined_df.groupby(['Retailer', 'Size Guide']).size().unstack(fill_value=0)
size_guide_percentages = size_guide_counts.div(size_guide_counts.sum(axis=1), axis=0) * 100

size_guide_percentages.plot(kind='bar', stacked=True, color=['#f4a582', '#92c5de'], figsize=(8,5))

# Labels
plt.title('Presence of Size Guide by Retailer (%)')
plt.ylabel('Percentage of Products')
plt.xlabel('Retailer')
plt.legend(title='Size Guide', labels=['No', 'Yes'])